{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95d750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "972e9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Preprocesssing/pre-processed.csv',header = 'infer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e91e282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>ClassLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman shouldnt complain cleaning house man alw...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rtboydatscoldtygadwnbad cuffindathoeinthe1st p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dawg ever fuck bitch start cry confused shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>look like tranny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  ClassLabel\n",
       "0  woman shouldnt complain cleaning house man alw...           2\n",
       "1  rtboydatscoldtygadwnbad cuffindathoeinthe1st p...           1\n",
       "2       dawg ever fuck bitch start cry confused shit           1\n",
       "3                                   look like tranny           1\n",
       "4     shit hear might true might faker bitch told ya           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c57984c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows and columns i.e. dimension of the dataset:  (24781, 2)\n",
      "\n",
      "column names of the dataset:  Index(['tweets', 'ClassLabel'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('number of rows and columns i.e. dimension of the dataset: ',df.shape)\n",
    "print('\\ncolumn names of the dataset: ',df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a873ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabel = df['ClassLabel']\n",
    "tweets = df.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285a9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c694eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    82,    68,    13],\n",
       "       [    0,     0,     0, ...,  8810,  8811,   385],\n",
       "       [    0,     0,     0, ...,   260,   906,    12],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    69, 19685,   502],\n",
       "       [    0,     0,     0, ...,     1,  4973,   435],\n",
       "       [    0,     0,     0, ...,   106,    53, 19689]], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(tweets)\n",
    "sequences = tokenizer.texts_to_sequences(tweets)\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b051cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, ClassLabel, test_size=0.2, random_state=110123184)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=110123184)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "114c86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e7b4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=max_sequence_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7cfe44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "91ca94ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "434/434 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.7968 - val_loss: 0.2472 - val_accuracy: 0.8561\n",
      "Epoch 2/50\n",
      "434/434 [==============================] - 1s 2ms/step - loss: 0.2009 - accuracy: 0.8956 - val_loss: 0.2220 - val_accuracy: 0.8771\n",
      "Epoch 3/50\n",
      "434/434 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9217 - val_loss: 0.2172 - val_accuracy: 0.8768\n",
      "Epoch 4/50\n",
      "434/434 [==============================] - 1s 2ms/step - loss: 0.1163 - accuracy: 0.9456 - val_loss: 0.2230 - val_accuracy: 0.8719\n",
      "Epoch 5/50\n",
      "434/434 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9616 - val_loss: 0.2308 - val_accuracy: 0.8702\n",
      "Epoch 6/50\n",
      "434/434 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9730 - val_loss: 0.2437 - val_accuracy: 0.8663\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cf2dc750>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "\n",
    "from imblearn.keras import BalancedBatchGenerator\n",
    "training_generator = BalancedBatchGenerator(X_train, y_train, batch_size=32, sampler=sampler)\n",
    "model.fit_generator(generator=training_generator, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "116d2055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 347us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.24      0.33       292\n",
      "           1       0.90      0.95      0.92      3851\n",
      "           2       0.77      0.71      0.74       814\n",
      "\n",
      "    accuracy                           0.87      4957\n",
      "   macro avg       0.73      0.64      0.67      4957\n",
      "weighted avg       0.86      0.87      0.86      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_test = y_test.T\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d237ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
