{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0e58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99c66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Preprocesssing/pre-processed.csv',header = 'infer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3963c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabel = df['ClassLabel']\n",
    "tweets = df.tweets\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "sequences = tokenizer.texts_to_sequences(tweets)\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ffcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, ClassLabel, test_size=0.2, random_state=110123184)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=110123184)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7993028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, hidden_units, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units[0], input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(hidden_units[1], activation='relu'))\n",
    "    model.add(Dense(hidden_units[2], activation='relu'))\n",
    "    model.add(Dense(hidden_units[3], activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f38d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 3 #len(np.unique(y_train))\n",
    "hidden_units = [128, 64, 32, 16]  # You can adjust these numbers as needed\n",
    "model = create_model(input_dim, hidden_units, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6fd3eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "434/434 [==============================] - 0s 799us/step - loss: 14.4468 - accuracy: 0.6402 - val_loss: 1.4850 - val_accuracy: 0.6772\n",
      "Epoch 2/100\n",
      "434/434 [==============================] - 0s 678us/step - loss: 1.0050 - accuracy: 0.7398 - val_loss: 0.8411 - val_accuracy: 0.7530\n",
      "Epoch 3/100\n",
      "434/434 [==============================] - 0s 664us/step - loss: 0.7350 - accuracy: 0.7656 - val_loss: 0.7420 - val_accuracy: 0.7660\n",
      "Epoch 4/100\n",
      "434/434 [==============================] - 0s 664us/step - loss: 0.7040 - accuracy: 0.7682 - val_loss: 0.7128 - val_accuracy: 0.7645\n",
      "Epoch 5/100\n",
      "434/434 [==============================] - 0s 667us/step - loss: 0.6691 - accuracy: 0.7733 - val_loss: 0.7137 - val_accuracy: 0.7702\n",
      "Epoch 6/100\n",
      "434/434 [==============================] - 0s 664us/step - loss: 0.6722 - accuracy: 0.7746 - val_loss: 0.6592 - val_accuracy: 0.7702\n",
      "Epoch 7/100\n",
      "434/434 [==============================] - 0s 656us/step - loss: 0.6559 - accuracy: 0.7759 - val_loss: 0.6744 - val_accuracy: 0.7621\n",
      "Epoch 8/100\n",
      "434/434 [==============================] - 0s 685us/step - loss: 0.6569 - accuracy: 0.7744 - val_loss: 0.6910 - val_accuracy: 0.7643\n",
      "Epoch 9/100\n",
      "434/434 [==============================] - 0s 689us/step - loss: 0.6510 - accuracy: 0.7775 - val_loss: 0.6644 - val_accuracy: 0.7697\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a8a93710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "training_generator = BalancedBatchGenerator(X_train, y_train, batch_size=batch_size, sampler=sampler)\n",
    "model.fit_generator(generator=training_generator, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96f20211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 280us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.00      0.01       292\n",
      "           1       0.78      1.00      0.87      3851\n",
      "           2       0.75      0.01      0.02       814\n",
      "\n",
      "    accuracy                           0.78      4957\n",
      "   macro avg       0.55      0.34      0.30      4957\n",
      "weighted avg       0.74      0.78      0.68      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "y_test = y_test.T\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a70fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
